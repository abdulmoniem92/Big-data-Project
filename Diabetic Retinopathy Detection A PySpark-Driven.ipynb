{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":418031,"sourceType":"datasetVersion","datasetId":131128}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:38:37.369257Z","iopub.execute_input":"2024-05-11T16:38:37.369515Z","iopub.status.idle":"2024-05-11T16:39:23.676182Z","shell.execute_reply.started":"2024-05-11T16:38:37.369490Z","shell.execute_reply":"2024-05-11T16:39:23.675047Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=b574f157168c2235747a08fbf2be84f91351b41d5b1d44f9e0fb69f1ca890896\n  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image, ImageOps\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import MultilayerPerceptronClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define image directory and label file paths\nimage_dir = \"/kaggle/input/diabetic-retinopathy-resized/resized_train_cropped/resized_train_cropped\"\nlabel_file = \"/kaggle/input/diabetic-retinopathy-resized/trainLabels_cropped.csv\"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Load label data\nlabels_df = pd.read_csv(label_file)\n\n# Group the labels by level and sample 400 samples from each level\nlabels_grouped = labels_df.groupby('level').apply(lambda x: x.sample(min(300, len(x))))\n\n# Define data augmentation for level 0 images\ndata_augmentation = ImageDataGenerator(\n    rotation_range=45,  # Random rotation up to 45 degrees\n    width_shift_range=0.3,  # Random width shift\n    height_shift_range=0.3,  # Random height shift\n    shear_range=0.3,  # Shear intensity\n    zoom_range=0.3,  # Random zoom\n    horizontal_flip=True,  # Random horizontal flip\n    fill_mode='nearest'  # Fill mode for new pixels\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess images with data augmentation\nimages = []\nlabels = []\nfor index, row in labels_grouped.iterrows():\n    image_path = os.path.join(image_dir, f\"{row['image']}.jpeg\")\n    img = Image.open(image_path)\n    img = img.resize((256, 256))\n    img_array = np.array(img) / 255.0\n    \n    # Apply data augmentation for level 0 images\n    if row['level'] == 0:\n        img_array = img_array.reshape((1,) + img_array.shape)  # Reshape for flow method\n        for _ in range(10):  # Augment 10 additional images for level 0\n            for batch in data_augmentation.flow(img_array, batch_size=1):\n                augmented_img = batch[0]\n                images.append(augmented_img)\n                labels.append(row['level'])\n                break  # Break after one iteration to avoid infinite loop\n    else:\n        images.append(img_array)\n        labels.append(row['level'])\n\nimages = np.array(images)\nlabels = np.array(labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode labels\nlabel_encoder = LabelEncoder()\nlabels = label_encoder.fit_transform(labels)\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n\n# Load pre-trained VGG16 model\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n\n# Unfreeze some top layers for fine-tuning\nfor layer in base_model.layers[:-4]:\n    layer.trainable = False\n\n# Add custom classifier layers\nx = Flatten()(base_model.output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)  # Add dropout for regularization\npredictions = Dense(5, activation='softmax')(x)\n\n# Create model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile model with lower learning rate\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train model with more epochs\nmodel.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n\n# Extract features using the trained model\nfeatures_train = model.predict(X_train)\nfeatures_test = model.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize Spark session\nspark = SparkSession.builder \\\n    .appName(\"ImageClassification\") \\\n    .getOrCreate()\n\n# Create Spark DataFrame for train and test data\ntrain_df = pd.DataFrame(features_train)\ntrain_df['label'] = y_train\ntrain_spark_df = spark.createDataFrame(train_df)\n\ntest_df = pd.DataFrame(features_test)\ntest_df['label'] = y_test\ntest_spark_df = spark.createDataFrame(test_df)\n\n# Define vector assembler\nassembler = VectorAssembler(inputCols=train_spark_df.columns[:-1], outputCol='features')\n\n# Transform train and test data\ntrain_spark_df = assembler.transform(train_spark_df)\ntest_spark_df = assembler.transform(test_spark_df)\n\n# Define MLP model with tuned hyperparameters\nlayers = [train_spark_df.schema['features'].metadata[\"ml_attr\"][\"num_attrs\"], 256, 128, 64, 5]\nmlp = MultilayerPerceptronClassifier(layers=layers, seed=42, blockSize=128, maxIter=100, stepSize=0.03)\n\n# Train MLP model with more iterations\nmlp_model = mlp.fit(train_spark_df)\n\n# Make predictions\npredictions = mlp_model.transform(test_spark_df)\n\n# Evaluate model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test Accuracy:\", accuracy)\n\n# Print the number of images\nprint(\"Number of images:\", len(images))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-11T16:39:23.678500Z","iopub.execute_input":"2024-05-11T16:39:23.679115Z","iopub.status.idle":"2024-05-11T16:47:32.862307Z","shell.execute_reply.started":"2024-05-11T16:39:23.679076Z","shell.execute_reply":"2024-05-11T16:47:32.861074Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-11 16:39:26.293586: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-11 16:39:26.293681: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-11 16:39:26.423365: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/tmp/ipykernel_34/452561247.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  labels_grouped = labels_df.groupby('level').apply(lambda x: x.sample(min(300, len(x))))\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2024-05-11 16:41:08.741036: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65536: 3.31777, expected 2.61172\n2024-05-11 16:41:08.741090: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65537: 5.10329, expected 4.39724\n2024-05-11 16:41:08.741099: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65538: 4.80913, expected 4.10308\n2024-05-11 16:41:08.741107: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65544: 5.33366, expected 4.62762\n2024-05-11 16:41:08.741114: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65545: 5.00267, expected 4.29663\n2024-05-11 16:41:08.741122: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65546: 4.93559, expected 4.22954\n2024-05-11 16:41:08.741130: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65547: 5.39283, expected 4.68678\n2024-05-11 16:41:08.741137: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65548: 5.61261, expected 4.90657\n2024-05-11 16:41:08.741145: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65549: 4.99846, expected 4.29241\n2024-05-11 16:41:08.741152: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65555: 5.67579, expected 4.96974\n2024-05-11 16:41:08.799105: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,64,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,256,256]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-11 16:41:08.799144: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-11 16:41:08.799153: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-11 16:41:08.799160: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-11 16:41:08.799167: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-11 16:41:08.799182: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-05-11 16:41:10.286460: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65536: 3.31777, expected 2.61172\n2024-05-11 16:41:10.286513: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65537: 5.10329, expected 4.39724\n2024-05-11 16:41:10.286524: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65538: 4.80913, expected 4.10308\n2024-05-11 16:41:10.286532: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65544: 5.33366, expected 4.62762\n2024-05-11 16:41:10.286540: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65545: 5.00267, expected 4.29663\n2024-05-11 16:41:10.286548: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65546: 4.93559, expected 4.22954\n2024-05-11 16:41:10.286556: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65547: 5.39283, expected 4.68678\n2024-05-11 16:41:10.286564: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65548: 5.61261, expected 4.90657\n2024-05-11 16:41:10.286572: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65549: 4.99846, expected 4.29241\n2024-05-11 16:41:10.286580: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 65555: 5.67579, expected 4.96974\n2024-05-11 16:41:10.340990: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,64,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,256,256]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n2024-05-11 16:41:10.345037: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,64,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,256,256]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-11 16:41:10.345071: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-11 16:41:10.345080: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-11 16:41:10.345087: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-11 16:41:10.345094: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-11 16:41:10.345111: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-05-11 16:41:10.345152: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.004369343s\nTrying algorithm eng15{k5=1,k6=0,k7=1,k10=1} for conv (f32[32,64,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,256,256]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 1/84\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38:22\u001b[0m 28s/step - accuracy: 0.4062 - loss: 1.7002","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1715445691.955539     116 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 130ms/step - accuracy: 0.6884 - loss: 1.3098 - val_accuracy: 0.7723 - val_loss: 0.4765\nEpoch 2/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.7622 - loss: 0.4714 - val_accuracy: 0.7812 - val_loss: 0.4460\nEpoch 3/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.7757 - loss: 0.4559 - val_accuracy: 0.7812 - val_loss: 0.4550\nEpoch 4/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.7892 - loss: 0.4300 - val_accuracy: 0.7932 - val_loss: 0.4238\nEpoch 5/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.7890 - loss: 0.4314 - val_accuracy: 0.7738 - val_loss: 0.6843\nEpoch 6/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.7749 - loss: 0.4788 - val_accuracy: 0.7768 - val_loss: 0.4625\nEpoch 7/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.7853 - loss: 0.4185 - val_accuracy: 0.7902 - val_loss: 0.4373\nEpoch 8/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.7745 - loss: 0.4344 - val_accuracy: 0.7872 - val_loss: 0.4354\nEpoch 9/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.7894 - loss: 0.4328 - val_accuracy: 0.7768 - val_loss: 0.4542\nEpoch 10/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.7858 - loss: 0.4292 - val_accuracy: 0.7961 - val_loss: 0.4248\nEpoch 11/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.7985 - loss: 0.3940 - val_accuracy: 0.7961 - val_loss: 0.4156\nEpoch 12/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8095 - loss: 0.3855 - val_accuracy: 0.8051 - val_loss: 0.4206\nEpoch 13/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8116 - loss: 0.3983 - val_accuracy: 0.8170 - val_loss: 0.3950\nEpoch 14/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8334 - loss: 0.3580 - val_accuracy: 0.7842 - val_loss: 0.4417\nEpoch 15/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8194 - loss: 0.3707 - val_accuracy: 0.8080 - val_loss: 0.4150\nEpoch 16/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.8269 - loss: 0.3622 - val_accuracy: 0.8021 - val_loss: 0.4263\nEpoch 17/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8366 - loss: 0.3423 - val_accuracy: 0.8170 - val_loss: 0.3844\nEpoch 18/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8470 - loss: 0.3334 - val_accuracy: 0.8125 - val_loss: 0.4343\nEpoch 19/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.8732 - loss: 0.2966 - val_accuracy: 0.8155 - val_loss: 0.4834\nEpoch 20/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8503 - loss: 0.3230 - val_accuracy: 0.8065 - val_loss: 0.4293\nEpoch 21/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8714 - loss: 0.2916 - val_accuracy: 0.8006 - val_loss: 0.5540\nEpoch 22/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.8622 - loss: 0.3161 - val_accuracy: 0.7783 - val_loss: 0.5603\nEpoch 23/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8319 - loss: 0.3795 - val_accuracy: 0.8110 - val_loss: 0.7090\nEpoch 24/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8706 - loss: 0.2861 - val_accuracy: 0.8155 - val_loss: 0.6579\nEpoch 25/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8766 - loss: 0.3225 - val_accuracy: 0.8095 - val_loss: 0.5123\nEpoch 26/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.8860 - loss: 0.2693 - val_accuracy: 0.8065 - val_loss: 0.6074\nEpoch 27/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8913 - loss: 0.2492 - val_accuracy: 0.8080 - val_loss: 0.5488\nEpoch 28/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8991 - loss: 0.2418 - val_accuracy: 0.8095 - val_loss: 0.6322\nEpoch 29/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8934 - loss: 0.2347 - val_accuracy: 0.8110 - val_loss: 0.8312\nEpoch 30/30\n\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.9213 - loss: 0.1828 - val_accuracy: 0.8036 - val_loss: 0.8555\n\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step\n\u001b[1m26/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step","output_type":"stream"},{"name":"stderr","text":"2024-05-11 16:46:47.369141: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.72144, expected 2.89031\n2024-05-11 16:46:47.369203: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.65806, expected 4.82693\n2024-05-11 16:46:47.369219: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 5.98376, expected 5.15263\n2024-05-11 16:46:47.369237: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 6.6283, expected 5.79717\n2024-05-11 16:46:47.369249: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.90088, expected 6.06975\n2024-05-11 16:46:47.369260: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 6.70007, expected 5.86894\n2024-05-11 16:46:47.369271: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.75339, expected 4.92226\n2024-05-11 16:46:47.369282: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 5.56626, expected 4.73513\n2024-05-11 16:46:47.369293: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 10: 5.14383, expected 4.3127\n2024-05-11 16:46:47.369303: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 5.89557, expected 5.06444\n2024-05-11 16:46:47.384879: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[8,64,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,3,256,256]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-11 16:46:47.384917: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-11 16:46:47.384930: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-11 16:46:47.384944: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-11 16:46:47.384957: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-11 16:46:47.384989: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-05-11 16:46:47.749134: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.72144, expected 2.89031\n2024-05-11 16:46:47.749187: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 5.65806, expected 4.82693\n2024-05-11 16:46:47.749202: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 5.98376, expected 5.15263\n2024-05-11 16:46:47.749220: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 6.6283, expected 5.79717\n2024-05-11 16:46:47.749233: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.90088, expected 6.06975\n2024-05-11 16:46:47.749244: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 6.70007, expected 5.86894\n2024-05-11 16:46:47.749255: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.75339, expected 4.92226\n2024-05-11 16:46:47.749265: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 5.56626, expected 4.73513\n2024-05-11 16:46:47.749276: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 10: 5.14383, expected 4.3127\n2024-05-11 16:46:47.749286: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 5.89557, expected 5.06444\n2024-05-11 16:46:47.764550: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[8,64,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[8,3,256,256]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-11 16:46:47.764581: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-11 16:46:47.764594: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-11 16:46:47.764605: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-11 16:46:47.764621: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-11 16:46:47.764674: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 353ms/step\n","output_type":"stream"},{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n24/05/11 16:46:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n24/05/11 16:47:11 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n24/05/11 16:47:27 WARN BlockManager: Asked to remove block broadcast_167, which does not exist\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.844047619047619\nNumber of images: 4200\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Make predictions on the training set\ntrain_predictions = mlp_model.transform(train_spark_df)\n\n# Evaluate train accuracy\ntrain_accuracy = evaluator.evaluate(train_predictions)\nprint(\"Train Accuracy:\",train_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T17:00:08.897253Z","iopub.execute_input":"2024-05-11T17:00:08.897998Z","iopub.status.idle":"2024-05-11T17:00:09.804923Z","shell.execute_reply.started":"2024-05-11T17:00:08.897944Z","shell.execute_reply":"2024-05-11T17:00:09.803898Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"[Stage 117:>                                                        (0 + 4) / 4]\r","output_type":"stream"},{"name":"stdout","text":"Train Accuracy: 0.9139880952380952\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}